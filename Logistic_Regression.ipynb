{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data selection\n",
    "The dataset is filtered by the classes *metal*$ \\cup$*punk* and *dance and electronica*, assigning 1 and 0 as their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%genre</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>...</th>\n",
       "      <th>var_timbre3</th>\n",
       "      <th>var_timbre4</th>\n",
       "      <th>var_timbre5</th>\n",
       "      <th>var_timbre6</th>\n",
       "      <th>var_timbre7</th>\n",
       "      <th>var_timbre8</th>\n",
       "      <th>var_timbre9</th>\n",
       "      <th>var_timbre10</th>\n",
       "      <th>var_timbre11</th>\n",
       "      <th>var_timbre12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classic pop and rock</td>\n",
       "      <td>TRFCOOU128F427AEC0</td>\n",
       "      <td>Blue Oyster Cult</td>\n",
       "      <td>Mes Dames Sarat</td>\n",
       "      <td>-8.697</td>\n",
       "      <td>155.007</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>246.33424</td>\n",
       "      <td>...</td>\n",
       "      <td>1255.514569</td>\n",
       "      <td>580.030472</td>\n",
       "      <td>598.485223</td>\n",
       "      <td>575.337671</td>\n",
       "      <td>322.068603</td>\n",
       "      <td>321.726029</td>\n",
       "      <td>232.700609</td>\n",
       "      <td>186.805303</td>\n",
       "      <td>181.938688</td>\n",
       "      <td>151.508011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classic pop and rock</td>\n",
       "      <td>TRNJTPB128F427AE9F</td>\n",
       "      <td>Blue Oyster Cult</td>\n",
       "      <td>Screams</td>\n",
       "      <td>-10.659</td>\n",
       "      <td>148.462</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>189.80526</td>\n",
       "      <td>...</td>\n",
       "      <td>2007.653070</td>\n",
       "      <td>1043.474073</td>\n",
       "      <td>585.694981</td>\n",
       "      <td>564.013736</td>\n",
       "      <td>510.177022</td>\n",
       "      <td>400.200186</td>\n",
       "      <td>365.119588</td>\n",
       "      <td>238.099708</td>\n",
       "      <td>197.933757</td>\n",
       "      <td>251.577525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classic pop and rock</td>\n",
       "      <td>TRLFJHA128F427AEEA</td>\n",
       "      <td>Blue Oyster Cult</td>\n",
       "      <td>Dance The Night Away</td>\n",
       "      <td>-13.494</td>\n",
       "      <td>112.909</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>158.19710</td>\n",
       "      <td>...</td>\n",
       "      <td>1204.856777</td>\n",
       "      <td>2736.520024</td>\n",
       "      <td>730.233239</td>\n",
       "      <td>665.203452</td>\n",
       "      <td>535.775111</td>\n",
       "      <td>439.335059</td>\n",
       "      <td>486.822970</td>\n",
       "      <td>265.333860</td>\n",
       "      <td>447.097987</td>\n",
       "      <td>251.880724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classic pop and rock</td>\n",
       "      <td>TRCQZAG128F427DB97</td>\n",
       "      <td>Blue Oyster Cult</td>\n",
       "      <td>Debbie Denise</td>\n",
       "      <td>-12.786</td>\n",
       "      <td>117.429</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>250.22649</td>\n",
       "      <td>...</td>\n",
       "      <td>809.755802</td>\n",
       "      <td>563.908070</td>\n",
       "      <td>492.803819</td>\n",
       "      <td>378.382799</td>\n",
       "      <td>372.875044</td>\n",
       "      <td>231.941957</td>\n",
       "      <td>246.313305</td>\n",
       "      <td>168.400152</td>\n",
       "      <td>85.282462</td>\n",
       "      <td>339.897173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classic pop and rock</td>\n",
       "      <td>TRNXMNM128F427DB8C</td>\n",
       "      <td>Blue Oyster Cult</td>\n",
       "      <td>(Don't Fear) The Reaper</td>\n",
       "      <td>-14.093</td>\n",
       "      <td>141.536</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>307.06893</td>\n",
       "      <td>...</td>\n",
       "      <td>1093.684935</td>\n",
       "      <td>343.556047</td>\n",
       "      <td>889.163314</td>\n",
       "      <td>218.111796</td>\n",
       "      <td>304.862864</td>\n",
       "      <td>178.352161</td>\n",
       "      <td>440.478867</td>\n",
       "      <td>142.669283</td>\n",
       "      <td>81.061326</td>\n",
       "      <td>208.355152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 %genre            track_id       artist_name  \\\n",
       "0  classic pop and rock  TRFCOOU128F427AEC0  Blue Oyster Cult   \n",
       "1  classic pop and rock  TRNJTPB128F427AE9F  Blue Oyster Cult   \n",
       "2  classic pop and rock  TRLFJHA128F427AEEA  Blue Oyster Cult   \n",
       "3  classic pop and rock  TRCQZAG128F427DB97  Blue Oyster Cult   \n",
       "4  classic pop and rock  TRNXMNM128F427DB8C  Blue Oyster Cult   \n",
       "\n",
       "                     title  loudness    tempo  time_signature  key  mode  \\\n",
       "0          Mes Dames Sarat    -8.697  155.007               1    9     1   \n",
       "1                  Screams   -10.659  148.462               1    4     0   \n",
       "2     Dance The Night Away   -13.494  112.909               1   10     0   \n",
       "3            Debbie Denise   -12.786  117.429               4    7     1   \n",
       "4  (Don't Fear) The Reaper   -14.093  141.536               4    9     0   \n",
       "\n",
       "    duration      ...       var_timbre3  var_timbre4  var_timbre5  \\\n",
       "0  246.33424      ...       1255.514569   580.030472   598.485223   \n",
       "1  189.80526      ...       2007.653070  1043.474073   585.694981   \n",
       "2  158.19710      ...       1204.856777  2736.520024   730.233239   \n",
       "3  250.22649      ...        809.755802   563.908070   492.803819   \n",
       "4  307.06893      ...       1093.684935   343.556047   889.163314   \n",
       "\n",
       "   var_timbre6  var_timbre7  var_timbre8  var_timbre9  var_timbre10  \\\n",
       "0   575.337671   322.068603   321.726029   232.700609    186.805303   \n",
       "1   564.013736   510.177022   400.200186   365.119588    238.099708   \n",
       "2   665.203452   535.775111   439.335059   486.822970    265.333860   \n",
       "3   378.382799   372.875044   231.941957   246.313305    168.400152   \n",
       "4   218.111796   304.862864   178.352161   440.478867    142.669283   \n",
       "\n",
       "   var_timbre11  var_timbre12  \n",
       "0    181.938688    151.508011  \n",
       "1    197.933757    251.577525  \n",
       "2    447.097987    251.880724  \n",
       "3     85.282462    339.897173  \n",
       "4     81.061326    208.355152  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('msd_genre_dataset.txt',header=9)\n",
    "dataf = data[(data['%genre']=='metal') | (data['%genre']=='punk') | (data['%genre']=='dance and electronica')]\n",
    "dataf = dataf.replace(to_replace='punk', value=True)\n",
    "dataf = dataf.replace(to_replace='metal', value=True)\n",
    "dataf = dataf.replace(to_replace='dance and electronica', value=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "It is easy to see that there are 30 quantitative features to in the dataset, so these are the ones used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dataf[dataf.keys()[4:]]\n",
    "Y = dataf['%genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First approach\n",
    "The first approach is to use the whole raw dataset to try and make predictions about the genres with a linear classifier. For this purpose, 20% of the data are reserved for validation, keeping in mind that approximately 10000 observations will leave enough data for the training and tessting sets.\n",
    "\n",
    "In the linear classifier approach the average stochastic gradient solver will be used, in accordance with the methodology of stochastic gradient descent learned in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2)\n",
    "linc = linear_model.LogisticRegression(solver='sag', max_iter=1000)\n",
    "linc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness of classification\n",
    "The goodness of the classification is evaluated by measuring the mean accuracy of the classifier in the test samples, and comparing it to the training samples to annalize the error and the overfitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on the training samples is: 0.842369\n",
      "The mean accuracy on the testing samples is: 0.841797\n"
     ]
    }
   ],
   "source": [
    "print('The mean accuracy on the training samples is: %f' %(linc.score(X_train, Y_train)))\n",
    "print('The mean accuracy on the testing samples is: %f' %(linc.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the classifier is good, as it achieves a reasonably good fit considering the used data, and the fact that there is no big difference between the accuracies on the testing and training datasets. However a better classifier in respect to accuracy may be found if previous treatment of data is performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardisation\n",
    "One of the simplest operations that can be performed with each of the features is to normalise it with respect ot their means and variances, which will allow for equal assignment of the \"weights\", as they will have the same scale.\n",
    "\n",
    "After doing this, the whole fitting process is repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_trains = scaler.transform(X_train)\n",
    "X_tests = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lincs = linear_model.LogisticRegression(solver='sag', max_iter=1000)\n",
    "lincs.fit(X_trains, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness\n",
    "The goodness of this classifier is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on the training samples is: 0.860440\n",
      "The mean accuracy on the testing samples is: 0.856445\n"
     ]
    }
   ],
   "source": [
    "print('The mean accuracy on the training samples is: %f' %(lincs.score(X_trains, Y_train)))\n",
    "print('The mean accuracy on the testing samples is: %f' %(lincs.score(X_tests, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this classifier is classifier is slightly better, however there is reason to think there may be better classifiers as not all features may be as important to the analysis.\n",
    "\n",
    "In order to solve this problem a principal component analysis is performed, and the fitting proceduere is repeated with this transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "In this part two fits will be performed, one with all components of the analysis are kept, and one where only the first components that explain at least 95% of the variance will be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PCA_scaler = decomposition.PCA().fit(X_train)\n",
    "X_traint = PCA_scaler.fit_transform(X_train)\n",
    "X_testt = PCA_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lincp = linear_model.LogisticRegression(solver='sag', max_iter=1000)\n",
    "lincp.fit(X_traint, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on the training samples is: 0.838828\n",
      "The mean accuracy on the testing samples is: 0.778320\n"
     ]
    }
   ],
   "source": [
    "print('The mean accuracy on the training samples is: %f' %(lincp.score(X_traint, Y_train)))\n",
    "print('The mean accuracy on the testing samples is: %f' %(lincp.score(X_testt, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case there is not a significant improvement on the goodness of the classifier and there is evidence of overfitting, as there is a bigger difference between the accuracy on the training samples and the accuracy on the testing samples. Given the amount of samples used for testing, this is a reasonable assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "As discussed previously, now only the most important components will be taken into account. These components are the first 4 as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.10040861e-01,   1.53387214e-01,   8.58806375e-02,\n",
       "         1.87632621e-02,   1.23080747e-02,   6.74138947e-03,\n",
       "         4.63492592e-03,   2.75615131e-03,   1.66082743e-03,\n",
       "         1.26293832e-03,   1.21468149e-03,   6.42956978e-04,\n",
       "         2.99442612e-04,   1.27186165e-04,   1.18095839e-04,\n",
       "         4.88292686e-05,   3.37638836e-05,   2.65223552e-05,\n",
       "         1.37429358e-05,   1.16913945e-05,   7.80895987e-06,\n",
       "         6.81759286e-06,   5.41041403e-06,   3.04847733e-06,\n",
       "         1.65771562e-06,   1.27503827e-06,   5.74825622e-07,\n",
       "         1.49417766e-07,   4.22143311e-08,   2.04898759e-08])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_scaler.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lincpd = linear_model.LogisticRegression(solver='sag')\n",
    "lincpd.fit(X_traint[:,:4], Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on the training samples is: 0.776679\n",
      "The mean accuracy on the testing samples is: 0.763184\n"
     ]
    }
   ],
   "source": [
    "print('The mean accuracy on the training samples is: %f' %(lincpd.score(X_traint[:,:4], Y_train)))\n",
    "print('The mean accuracy on the testing samples is: %f' %(lincpd.score(X_testt[:,:4], Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using only the most important components, the overfitting problem is solved, however the accuracy is signifficantly worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The last attempt\n",
    "It can be seen that only the cases where standardisation or dimensionality reduction were used presented convergence, this is due to the big difference in variances among the features, when standardisation was not performed, which caused undesirable oscillations in the gradient, which delayed the convergence.\n",
    "\n",
    "There are two possible solutions for this, one is to perform standardisation on the PCA transformation (which has the advantage of giving uncorrelated features) and the other one is to use a different sover that allows for faster convergence. Both approaches will be shown next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardisation of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCA_rescaler = preprocessing.StandardScaler().fit(X_traint)\n",
    "X_traintre = PCA_rescaler.transform(X_traint)\n",
    "X_testtre = PCA_rescaler.transform(X_testt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lincpr = linear_model.LogisticRegression(solver='sag', max_iter=1000)\n",
    "lincpr.fit(X_traintre, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on the training samples is: 0.860440\n",
      "The mean accuracy on the testing samples is: 0.750488\n"
     ]
    }
   ],
   "source": [
    "print('The mean accuracy on the training samples is: %f' %(lincpr.score(X_traintre, Y_train)))\n",
    "print('The mean accuracy on the testing samples is: %f' %(lincpr.score(X_testtre, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight improvement with respect to the PCA decomposition without additional treatment, however there is evidence of overfitting which gisves a significantly worse performance of this approach with respect to only doing standardisation. This may be improved with dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on the training samples is: 0.782051\n",
      "The mean accuracy on the testing samples is: 0.771484\n"
     ]
    }
   ],
   "source": [
    "lincprd = linear_model.LogisticRegression(solver='sag', max_iter=1000)\n",
    "lincprd.fit(X_traintre[:,:4], Y_train)\n",
    "print('The mean accuracy on the training samples is: %f' %(lincprd.score(X_traintre[:,:4], Y_train)))\n",
    "print('The mean accuracy on the testing samples is: %f' %(lincprd.score(X_testtre[:,:4], Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the overfitting problem is corrected, but the performance is still signifficantly worse. In this case it is not be worth all the trouble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The recommended solver\n",
    "In this case the expected results will be similar to the standardisation cases, as the same minimum will be reached even though the adjusted parameters will be in a different scale.\n",
    "\n",
    "The default solver for the function LogisticRegression is a coordinate descent algorithm, not seen in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lincN = linear_model.LogisticRegression(max_iter=1000)\n",
    "lincN.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy on the training samples is: 0.859951\n",
      "The mean accuracy on the testing samples is: 0.856445\n"
     ]
    }
   ],
   "source": [
    "print('The mean accuracy on the training samples is: %f' %(lincN.score(X_train, Y_train)))\n",
    "print('The mean accuracy on the testing samples is: %f' %(lincN.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, the accuracy is very similar to the one found through standardisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "The best accuracy is given by standardising the features and using the whole dataset, as it yields the best accuracy of the different approaches without the overfitting.\n",
    "\n",
    "Given the amount of samples reserved for testing, there is high probability that the estimated accuracy of the algorithm is close to the real accuracy.\n",
    "\n",
    "Standardisation of the samples helps with the convergence of the algorithms by eliminating undesirable oscillations due to high eccentricities given by the feature scales.\n",
    "\n",
    "Use of transformations like PCA should be handled with care as the use of a number of component equal to the number of features leads to overfitting.\n",
    "\n",
    "In this case, dimensionality reduction is not really necessary as there is a small number of features with respect to the number of samples and the computational power available is more than enough to handle the problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
